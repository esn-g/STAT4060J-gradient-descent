{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (80,) (20,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m4\u001b[39m))  \u001b[38;5;66;03m# Input data\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Noisy outputs\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Initial hyperparameters: log(sigma_s), log(sigma_n), log(diag(W))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m initial_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1.0\u001b[39m] \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (80,) (20,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X=data.data\n",
    "y=data.target.reshape(-1,1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def logistic_vanilla(X, y, num_iterations=10000, learning_rate=1e-2):\n",
    "    r, c = X.shape\n",
    "    X = np.hstack((np.ones((r, 1)), X))\n",
    "    beta = 2 * np.random.randn(c + 1, 1) - 1\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        predictions = sigmoid(X.dot(beta))\n",
    "        gradient = X.T.dot(y - predictions)\n",
    "        beta += learning_rate * gradient\n",
    "\n",
    "    return beta\n",
    "\n",
    "def logistic_polyak(X, y, num_iterations=10000, learning_rate=1e-2, momentum=0.9):\n",
    "    r, c = X.shape\n",
    "    X = np.hstack((np.ones((r, 1)), X))\n",
    "    beta = 2 * np.random.randn(c + 1, 1) - 1\n",
    "    velocity = np.zeros_like(beta)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        predictions = sigmoid(X.dot(beta))\n",
    "        gradient = X.T.dot(y - predictions)\n",
    "        velocity = momentum * velocity + learning_rate * gradient\n",
    "        beta += velocity\n",
    "\n",
    "    return beta\n",
    "\n",
    "def logistic_nesterov(X, y, num_iterations=10000, learning_rate=1e-2, momentum=0.9):\n",
    "    r, c = X.shape\n",
    "    X = np.hstack((np.ones((r, 1)), X))\n",
    "    beta = 2 * np.random.randn(c + 1, 1) - 1\n",
    "    velocity = np.zeros_like(beta)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Lookahead position\n",
    "        lookahead_beta = beta + momentum * velocity\n",
    "        predictions = sigmoid(X.dot(lookahead_beta))\n",
    "        gradient = X.T.dot(y - predictions)\n",
    "        velocity = momentum * velocity + learning_rate * gradient\n",
    "        beta += velocity\n",
    "\n",
    "    return beta\n",
    "\n",
    "# Generate synthetic dataset\n",
    "n, p = 1000, 5\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "beta_true = np.ones((p, 1))\n",
    "Y = (np.random.uniform(0, 1, (n, 1)) < sigmoid(X.dot(beta_true))).astype(float)\n",
    "\n",
    "# Run logistic regression using the different gradient descent methods\n",
    "beta_vanilla = logistic_vanilla(X, Y)\n",
    "beta_polyak = logistic_polyak(X, Y)\n",
    "beta_nesterov = logistic_nesterov(X, Y)\n",
    "\n",
    "print(\"Vanilla Gradient Descent Beta:\", beta_vanilla.ravel())\n",
    "print(\"Polyak Momentum Beta:\", beta_polyak.ravel())\n",
    "print(\"Nesterov Accelerated Gradient Beta:\", beta_nesterov.ravel())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
